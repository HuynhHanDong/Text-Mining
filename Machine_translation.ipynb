{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76be19cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from rouge import Rouge\n",
    "\n",
    "# Load model and tokenizer\n",
    "device = torch.device(\"cpu\")\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-vi\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name, use_safetensors=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab76edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_en_to_vi(sentence: str) -> str:\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True)\n",
    "    translated = model.generate(**inputs)\n",
    "    return tokenizer.decode(translated[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400412ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentences, translate_func):\n",
    "    \"\"\"\n",
    "    Evaluate translation quality with BLEU, METEOR, and ROUGE.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sentences: list of (english_sentence, reference_vietnamese_sentence)\n",
    "    translate_func: the translate function\n",
    "    \"\"\"\n",
    "    rouge = Rouge()\n",
    "    all_references, all_predictions = [], []\n",
    "    bleu_scores, meteor_scores, rouge_scores = [], [], []\n",
    "\n",
    "    for en_sentence, ref_vi in sentences:\n",
    "        pred_vi = translate_func(en_sentence)\n",
    "        \n",
    "        # BLEU\n",
    "        # Collect for corpus BLEU\n",
    "        all_references.append([ref_vi.split()])  # BLEU expects list of list\n",
    "        all_predictions.append(pred_vi.split())\n",
    "\n",
    "        # Sentence-level BLEU\n",
    "        bleu = sentence_bleu([ref_vi.split()], pred_vi.split())\n",
    "        bleu_scores.append(bleu)\n",
    "        \n",
    "        # METEOR\n",
    "        meteor = meteor_score([ref_vi.split()], pred_vi.split())\n",
    "        meteor_scores.append(meteor)\n",
    "        \n",
    "        # ROUGE-L F1\n",
    "        rouge_result = rouge.get_scores(pred_vi, ref_vi)[0][\"rouge-l\"][\"f\"]\n",
    "        rouge_scores.append(rouge_result)\n",
    "        \n",
    "        print(f\"\\nEN: {en_sentence}\")\n",
    "        print(f\"Reference VI: {ref_vi}\")\n",
    "        print(f\"Predicted VI: {pred_vi}\")\n",
    "        print(f\"BLEU: {bleu:.4f}, METEOR: {meteor:.4f}, ROUGE-L F1: {rouge_result:.4f}\")\n",
    "\n",
    "    # Corpus BLEU\n",
    "    corpus_bleu_score = corpus_bleu(all_references, all_predictions)\n",
    "    \n",
    "    print(\"\\n--- AVERAGE METRICS ---\")\n",
    "    print(f\"Sentence-level BLEU (avg): {sum(bleu_scores)/len(bleu_scores):.4f}\")\n",
    "    print(f\"Corpus BLEU: {corpus_bleu_score:.4f}\")\n",
    "    print(f\"METEOR: {sum(meteor_scores)/len(meteor_scores):.4f}\")\n",
    "    print(f\"ROUGE-L F1: {sum(rouge_scores)/len(rouge_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31152e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HanDong\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\HanDong\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\HanDong\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EN: The weather is nice today.\n",
      "Reference VI: Thời tiết hôm nay thật đẹp.\n",
      "Predicted VI: Hôm nay thời tiết đẹp quá.\n",
      "BLEU: 0.0000, METEOR: 0.6250, ROUGE-L F1: 0.3333\n",
      "\n",
      "EN: I love learning new languages.\n",
      "Reference VI: Tôi thích học những ngôn ngữ mới.\n",
      "Predicted VI: Tôi thích học ngoại ngữ mới.\n",
      "BLEU: 0.0000, METEOR: 0.7014, ROUGE-L F1: 0.7692\n",
      "\n",
      "EN: This book is very interesting.\n",
      "Reference VI: Cuốn sách này rất thú vị.\n",
      "Predicted VI: Cuốn sách này rất thú vị.\n",
      "BLEU: 1.0000, METEOR: 0.9977, ROUGE-L F1: 1.0000\n",
      "\n",
      "EN: Can you help me with my homework?\n",
      "Reference VI: Bạn có thể giúp tôi làm bài tập về nhà không?\n",
      "Predicted VI: Cậu giúp tớ làm bài tập được không?\n",
      "BLEU: 0.0000, METEOR: 0.4168, ROUGE-L F1: 0.5263\n",
      "\n",
      "--- AVERAGE METRICS ---\n",
      "Sentence-level BLEU (avg): 0.2500\n",
      "Corpus BLEU: 0.3320\n",
      "METEOR: 0.6852\n",
      "ROUGE-L F1: 0.6572\n"
     ]
    }
   ],
   "source": [
    "dataset = [\n",
    "    (\"The weather is nice today.\", \"Thời tiết hôm nay thật đẹp.\"),\n",
    "    (\"I love learning new languages.\", \"Tôi thích học những ngôn ngữ mới.\"),\n",
    "    (\"This book is very interesting.\", \"Cuốn sách này rất thú vị.\"),\n",
    "    (\"Can you help me with my homework?\", \"Bạn có thể giúp tôi làm bài tập về nhà không?\"),\n",
    "]\n",
    "\n",
    "evaluate(dataset, translate_func=translate_en_to_vi)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
