{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b524401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1df691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Lowercase and remove non-alphanumeric characters except spaces\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "961c59f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram_model(text, n):\n",
    "    words = text.split()\n",
    "    model = defaultdict(Counter)\n",
    "\n",
    "    for i in range(len(words) - n + 1):\n",
    "        # Get the context (first n-1 words)\n",
    "        context = tuple(words[i:i+n-1])\n",
    "        # Get the next word\n",
    "        next_word = words[i+n-1]\n",
    "        # Add to model\n",
    "        model[context][next_word] += 1\n",
    "    \n",
    "    return dict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d5b2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, seed, length):\n",
    "    # Preprocess seed and split into words\n",
    "    seed_words = preprocess_text(seed).split()\n",
    "    result = seed_words.copy()\n",
    "\n",
    "    # Determine n-gram order from model\n",
    "    n_order  = len(next(iter(model))) + 1 if model else 1\n",
    "\n",
    "    # Generate text\n",
    "    for _ in range(length):\n",
    "        # Get current context (last n-1 words)\n",
    "        if len(result) >= n_order - 1:\n",
    "            context = tuple(result[-(n_order-1):])\n",
    "        else:\n",
    "            # If we don't have enough context, use what we have\n",
    "            context = tuple(result)\n",
    "\n",
    "        # Find possible next words\n",
    "        if context in model:\n",
    "            next_words = model[context]\n",
    "            # Create weighted list for random selection\n",
    "            words = list(next_words.keys())\n",
    "            weights = list(next_words.values())\n",
    "            \n",
    "            # Randomly select next word based on probability\n",
    "            next_word = random.choices(words, weights=weights)[0]\n",
    "            result.append(next_word)\n",
    "        else:\n",
    "            # If context not found, try with shorter context or pick random word\n",
    "            found = False\n",
    "            for i in range(1, len(context)):\n",
    "                shorter_context = context[i:]\n",
    "                if shorter_context in model:\n",
    "                    next_words = model[shorter_context]\n",
    "                    words = list(next_words.keys())\n",
    "                    weights = list(next_words.values())\n",
    "                    next_word = random.choices(words, weights=weights)[0]\n",
    "                    result.append(next_word)\n",
    "                    found = True\n",
    "                    break\n",
    "            \n",
    "            if not found:\n",
    "                # Pick a random word from all possible words in the model\n",
    "                all_words = []\n",
    "                for counter in model.values():\n",
    "                    all_words.extend(counter.keys())\n",
    "                if all_words:\n",
    "                    next_word = random.choice(all_words)\n",
    "                    result.append(next_word)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20630753",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/ngram.txt', 'r') as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "processed_text = preprocess_text(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2be323e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 'natural'\n",
      "Length: 100 words\n",
      "natural kind important language depth x entity to a fencedin area not a writing instrument named entity recognition which extracts the names of people places and other entities from text machine translation and speech recognition stemming this divides words with inflection in them into root forms for example an algorithm is developed to process partofspeech tagging words are divided by white spaces sentence breaking this sentence into parts of speech they correspond to such as french without human intervention natural language processing algorithm is developed to process partofspeech tagging words are tagged based on the text remain lemmatization and stemming lemmatization\n",
      "------------------------------\n",
      "Seed: 'language'\n",
      "Length: 100 words\n",
      "language determine user taking cloud the for the same for instance in the pen the word bark as well as the text so unique words that can be used to classify text for all instances of mcdonalds as two separate entities one a restaurant and one a restaurant and one a restaurant and one a person scans a handwritten document into a computer the algorithm would recognize the root of the text as well as all its conjugations the algorithm would recognize the two instances of mcdonalds as two separate entities one a person scans a handwritten document into a computer\n",
      "------------------------------\n",
      "Seed: 'data'\n",
      "Length: 100 words\n",
      "data based correlations by such early of kind it sentence nlp and that machine learning algorithms have historically been bad at interpreting now with improvements in deep learning and neural networks natural language generation this process a computer program to process their respective inputs at some point in processing the input is converted to code that the use of the information created online and stored in databases is natural human language as humans have different sensors such as french without human intervention natural language processing has existed for more complex downstream processing tasks word segmentation this divides words with inflection in\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# N = 3\n",
    "model = build_ngram_model(processed_text, n=3)\n",
    "seeds = ['natural', 'language', 'data']  # Starting word or phrase\n",
    "length = 100  # Length of the generated text\n",
    "\n",
    "# Generate and print text\n",
    "for seed in seeds:\n",
    "    print(f\"Seed: '{seed}'\")\n",
    "    print(f\"Length: {length} words\")\n",
    "    generated = generate_text(model, seed, length)\n",
    "    print(generated)\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83ef584c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 'natural'\n",
      "Length: 100 words\n",
      "natural language processing tasks word sense disambiguation this derives the data is analyzing text for all instances of needing to perform tasks word removal common words are two separate entities that text and research and eyes to as well as google translate me can be part of those phrases to understand the main functions listed above are several ways this function automatically generating news article and identify relevant correlations and annual reports that frequently appear in the sentence boundaries in data theyre essentially the following customer is useful for example the following customer feedback analysis and nlp uses either rulebased approach\n",
      "------------------------------\n",
      "Seed: 'language'\n",
      "Length: 100 words\n",
      "language generation nlg nlg uses patterns in payment transactions to understand them into parts of a python library for example of natural language processing applies algorithms to texts to take realworld input is keyword extraction which pulls the language generation nlg uses patterns in processing are visually the pen the input process a type of sentences morphological segmentation this can understand the semantics behind words and eyes to understand the words that machine learning and assembling this approach where the algorithm can understand natural language processing algorithms perform tasks word barked the following parsing this is natural language as more rulebased\n",
      "------------------------------\n",
      "Seed: 'data'\n",
      "Length: 100 words\n",
      "data so unique words in chatbots voice assistant will still be automatically write a summary of big data in the cloud computing insurance should be useful for natural language processing the candidate sourcing and simplifies different semantics of findings from a component of natural language processing requires some of the functions listed above are many of simple keyword extraction this process partofspeech tagging words into a voice assistant instead of speech recognition ner determines words with a natural language processing earlier approaches to read and nlp is in the bi platform another language processing can detect text for example when a\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# # N = 2\n",
    "model = build_ngram_model(processed_text, n=2)\n",
    "seeds = ['natural', 'language', 'data']  # Starting word or phrase\n",
    "length = 100  # Length of the generated text\n",
    "\n",
    "# Generate and print text\n",
    "for seed in seeds:\n",
    "    print(f\"Seed: '{seed}'\")\n",
    "    print(f\"Length: {length} words\")\n",
    "    generated = generate_text(model, seed, length)\n",
    "    print(generated)\n",
    "    print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
